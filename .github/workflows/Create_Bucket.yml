name: Create s3 Bucket

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Action to perform on S3 bucket"
        required: true
        type: choice
        options:
          - Create_s3_Bucket
          - Destroy_s3_Bucket
        default: "Create_s3_Bucket"
      bucket:
        description: "S3 bucket name - must be unique"
        required: true
        type: string
      aws_account:
        description: "AWS Account to use"
        required: true
        type: choice
        options:
          - Test
          - Development
          - Production
      region:
        description: "AWS region"
        required: true
        type: choice
        options:
          - us-east-1
          - us-east-2
          - us-west-1
          - us-west-2
          - ca-central-1
  
  
  workflow_call:
    inputs:
      action:
        description: "Action to perform on S3 bucket"
        required: true
        type: string
      bucket:
        description: "S3 bucket name"
        required: true
        type: string
      aws_account:
        description: "AWS Account to use"
        required: true
        type: string
      region:
        description: "AWS region"
        required: true
        type: string

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_DEFAULT_REGION: ${{ inputs.region }}
      AWS_REGION: ${{ inputs.region }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.12.2"

      - name: Configure AWS Credentials for Test Account
        if: inputs.aws_account == 'Test'
        uses: aws-actions/configure-aws-credentials@v4.0.2
        with:
          aws-access-key-id: "${{ secrets.AWS_ACCESS_KEY_ID_TEST }}"
          aws-secret-access-key: "${{ secrets.AWS_SECRET_ACCESS_KEY_TEST }}"
          aws-region: ${{ inputs.region }}
          mask-aws-account-id: false

      - name: Configure AWS Credentials for Production Account
        if: inputs.aws_account == 'Production'
        uses: aws-actions/configure-aws-credentials@v4.0.2
        with:
          aws-access-key-id: "${{ secrets.AWS_ACCESS_KEY_ID_PRODUCTION }}"
          aws-secret-access-key: "${{ secrets.AWS_SECRET_ACCESS_KEY_PRODUCTION }}"
          aws-region: ${{ inputs.region }}
          mask-aws-account-id: false

      - name: Configure AWS Credentials for Dev Account
        if: inputs.aws_account == 'Development'
        uses: aws-actions/configure-aws-credentials@v4.0.2
        with:
          aws-access-key-id: "${{ secrets.AWS_ACCESS_KEY_ID_DEV }}"
          aws-secret-access-key: "${{ secrets.AWS_SECRET_ACCESS_KEY_DEV }}"
          aws-region: ${{ inputs.region }}
          mask-aws-account-id: false

      - name: Force Region Configuration Override
        run: |
          echo "Forcing region configuration to: ${{ inputs.region }}"
          aws configure set region ${{ inputs.region }}
          aws configure set default.region ${{ inputs.region }}
          export AWS_DEFAULT_REGION="${{ inputs.region }}"
          export AWS_REGION="${{ inputs.region }}"
          echo "Current AWS configuration:"
          aws configure list
          echo "Testing region with STS call:"
          aws sts get-caller-identity --region ${{ inputs.region }}

      - name: Write Terraform config for S3 bucket creation
        env:
          TF_VAR_region: ${{ inputs.region }}
        run: |
          echo "Creating Terraform config for region: ${{ inputs.region }}"
          export AWS_DEFAULT_REGION="${{ inputs.region }}"
          export AWS_REGION="${{ inputs.region }}"
          cat > bucket-main.tf <<EOF
          terraform {
            required_providers {
              aws = {
                source  = "hashicorp/aws"
                version = "~> 5.0"
              }
            }
          }

          provider "aws" {
            region = "us-east-1"
          }

          # Create S3 bucket for tfstate with object lock enabled
          resource "aws_s3_bucket" "tf_state" {
            bucket        = "${{ inputs.bucket }}"
            object_lock_enabled = true           
          }

          # Enable versioning
          resource "aws_s3_bucket_versioning" "tf_state" {
            bucket = aws_s3_bucket.tf_state.id
            versioning_configuration {
              status = "Enabled"
            }
          }

          # Enable encryption
          resource "aws_s3_bucket_server_side_encryption_configuration" "tf_state" {
            bucket = aws_s3_bucket.tf_state.id
            rule {
              apply_server_side_encryption_by_default {
                sse_algorithm = "AES256"
              }
            }
          }

          EOF

      - name: Verify AWS Configuration
        run: |
          echo "AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION"
          echo "AWS_REGION: $AWS_REGION"
          echo "Input region: ${{ inputs.region }}"
          aws configure list
          aws sts get-caller-identity

      - name: Terraform Init
        env:
          AWS_DEFAULT_REGION: ${{ inputs.region }}
          AWS_REGION: ${{ inputs.region }}
        run: |
          export AWS_DEFAULT_REGION="${{ inputs.region }}"
          export AWS_REGION="${{ inputs.region }}"
          terraform init

      - name: Empty S3 bucket before destruction
        if: inputs.action == 'Destroy_s3_Bucket'
        run: |
          # Remove all objects and versions from the bucket
          aws s3 rm s3://${{ inputs.bucket }} --recursive
          
          # Remove all object versions (for versioned buckets)
          aws s3api list-object-versions --bucket "${{ inputs.bucket }}" --query 'Versions[].{Key:Key,VersionId:VersionId}' --output text | while read key version; do
            if [ ! -z "$key" ] && [ ! -z "$version" ]; then
              aws s3api delete-object --bucket "${{ inputs.bucket }}" --key "$key" --version-id "$version"
            fi
          done
          
          # Remove all delete markers
          aws s3api list-object-versions --bucket "${{ inputs.bucket }}" --query 'DeleteMarkers[].{Key:Key,VersionId:VersionId}' --output text | while read key version; do
            if [ ! -z "$key" ] && [ ! -z "$version" ]; then
              aws s3api delete-object --bucket "${{ inputs.bucket }}" --key "$key" --version-id "$version"
            fi
          done

      - name: Import existing resources 
        if: inputs.action == 'Destroy_s3_Bucket'
        run: |
          terraform import aws_s3_bucket.tf_state "${{ inputs.bucket }}" 
          terraform import aws_s3_bucket_versioning.tf_state "${{ inputs.bucket }}" 
          terraform import aws_s3_bucket_server_side_encryption_configuration.tf_state "${{ inputs.bucket }}" 

      - name: Terraform Apply
        if: inputs.action == 'Create_s3_Bucket'
        env:
          AWS_DEFAULT_REGION: ${{ inputs.region }}
          AWS_REGION: ${{ inputs.region }}
        run: |
          export AWS_DEFAULT_REGION="${{ inputs.region }}"
          export AWS_REGION="${{ inputs.region }}"
          terraform apply -auto-approve

      - name: Create empty nagios/terraform.tfstate file
        if: inputs.action == 'Create_s3_Bucket'
        run: |
          # Create an empty terraform state file for nagios (not the bucket creation state)
          echo '{}' > empty_nagios_state.json
          
          # Upload the empty state file to the nagios folder
          aws s3 cp empty_nagios_state.json s3://${{ inputs.bucket }}/nagios/terraform.tfstate
          echo "Created empty nagios/terraform.tfstate file in bucket ${{ inputs.bucket }}"

      - name: Terraform Destroy_s3_Bucket
        if: inputs.action == 'Destroy_s3_Bucket'
        run: terraform destroy -auto-approve 


